{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2214fd4-983e-43f1-a1c2-8f4d8b6bea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy bibliotek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pliki CSV umieszczone w folderze data\n",
    "uczestnicy = pd.read_csv('data/PPK_Uczestnicy.csv', sep=';')\n",
    "pracodawcy = pd.read_csv('data/PPK_Pracodawcy.csv',sep=';')\n",
    "\n",
    "# Mergowanie dwóch csv\n",
    "df = pd.merge(\n",
    "    uczestnicy,\n",
    "    pracodawcy,\n",
    "    how='left',\n",
    "    left_on='EMPL_ID',\n",
    "    right_on='ID'\n",
    ")\n",
    "\n",
    "# Dropowanie niepotrzebnych kolumn\n",
    "df.drop(columns=['MEMBER_ID','LOGICAL_FACTOR_1','LOGICAL_FACTOR_2','ID','PKD_CODE','PPK_BANK','NUMERICAL_VALUE'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0275e3-69c6-43fc-a2b0-8237c339402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kształt danych i nazwy kolumn\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilość NaNów w każej kolumnie\n",
    "for col in df.columns:\n",
    "    print( col, df[col].isna().sum() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3be916-424b-4cfe-b0d2-50182e378dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grouping other nationalities into one category '0'\n",
    "unique_nat = df['NATIONALITY'].unique()\n",
    "for val in unique_nat:\n",
    "    suma = ( df['NATIONALITY'].values == val ).sum()\n",
    "    if suma < 500:\n",
    "        df.loc[df.NATIONALITY == val, 'NATIONALITY'] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018262bd-dbf9-4d31-9d8e-25256145a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count values dla poszczególnych kolumn\n",
    "# dzięki temu możemy rozważyć które wartości ktegoryczne odrzucić jako nieistotne outliery i nie tworzyc dla nich dodatkowych dummy variables\n",
    "# prawdopodobnie można poucinać małe wartości dla regionów podobnie jak jest zrobione dla narodowości\n",
    "cat_cols = ['IS_SUSPENDED', 'SEX', 'NATIONALITY', 'HAS_AE', 'HAS_AW', 'HAS_IP', 'PPK_STAGE', 'REGION_CODE', 'VOIVODESHIP', 'COMPANY_SIZE', 'COMPANY_TYPE']\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    print( df[cat_col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3408384-9b64-4c77-97e3-5e3b8d237f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniklne wartości w każdej z kolumn - UWAGA - dat jest w chuj czekamy na pojemniki\n",
    "for col in df.columns:\n",
    "    print( col, df[col].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673a2a4-78c7-4cfa-893a-6a8e82695414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd20d01-05f7-4745-8258-a62b13a25953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamian danych kategorycznych na dummy variables - tworzymy nową kolumnę na każdy możliwy output kolumny, porównaj poprzednią i następną komórkę\n",
    "df = pd.get_dummies(df, columns = ['SEX', 'COMPANY_SIZE', 'COMPANY_TYPE', 'VOIVODESHIP'], prefix = ['SEX', 'COMPANY_SIZE', 'COMPANY_TYPE', 'VOIVODESHIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cd8a7-b7fc-4c30-a78a-959074bebc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1059e0f4-4480-4dd2-86e5-6ce3daf00cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix jak coś chuja widać bo jest dużo kolumn\n",
    "corr = df.corr()# plot the heatmap\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=sns.diverging_palette(220, 20, as_cmap=True))\n",
    "# corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
