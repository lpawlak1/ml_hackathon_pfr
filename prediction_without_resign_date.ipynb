{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy bibliotek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mergujemy to i tamto ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pliki CSV umieszczone w folderze data\n",
    "uczestnicy = pd.read_csv('data/PPK_Uczestnicy.csv', sep=';')\n",
    "pracodawcy = pd.read_csv('data/PPK_Pracodawcy.csv', sep=';')\n",
    "\n",
    "# Mergowanie dwóch csv\n",
    "df = pd.merge(\n",
    "    uczestnicy,\n",
    "    pracodawcy,\n",
    "    how='left',\n",
    "    left_on='EMPL_ID',\n",
    "    right_on='ID'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyrzucamy niepotrzebne kolumny "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropowanie niepotrzebnych kolumn\n",
    "df.drop(columns=['MEMBER_ID',\n",
    "                 'EMPL_ID',  \n",
    "                 'LOGICAL_FACTOR_1',\n",
    "                 'LOGICAL_FACTOR_2',\n",
    "                 'ID',\n",
    "                 'PKD_CODE',\n",
    "                 'PPK_BANK',\n",
    "                 'NUMERICAL_VALUE'], inplace = True)\n",
    "\n",
    "# Te kolumny niby jakoś możnaby wykorzystać, ale wątpliwe, że coś by z tego wynikło\n",
    "df.drop(columns =[\"CREATED_AT\", \n",
    "                  \"UOZ_START_DATE\", \n",
    "                  \"UOP_SIGN_DATE\", \n",
    "                  'REGION_CODE',\n",
    "                  'WORK_START', \n",
    "                  'WORK_STOP'], inplace = True)\n",
    "\n",
    "# no i to trzeba wyrzucic heh\n",
    "df.drop(columns = [\"RESIGN_DATE\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age to int\n",
    "\n",
    "def to_int(age):\n",
    "    age = age[:age.find(\",\")]\n",
    "    return int(age)\n",
    "\n",
    "df[\"AGE\"] = df[\"AGE\"].apply(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping other nationalities into one category '0'\n",
    "\n",
    "unique_nat = df['NATIONALITY'].unique()\n",
    "for val in unique_nat:\n",
    "    suma = ( df['NATIONALITY'].values == val ).sum()\n",
    "    if suma < 5000:\n",
    "        df.loc[df.NATIONALITY == val, 'NATIONALITY'] = 0       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiana danych kategorycznych na dummy variables - tworzymy nową kolumnę na każdy możliwy output kolumny, porównaj poprzednią i następną komórkę\n",
    "df = pd.get_dummies(df, columns = ['SEX', 'COMPANY_SIZE', 'COMPANY_TYPE', 'VOIVODESHIP', 'NATIONALITY','PPK_STAGE'], \n",
    "                         prefix = ['SEX', 'COMPANY_SIZE', 'COMPANY_TYPE', 'VOIVODESHIP', 'NATIONALITY','PPK_STAGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# duration - czas od zapisania się do teraz\n",
    "def find_period(start):\n",
    "    stop = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    start_year, start_month, start_day = map(int, start.split('-'))\n",
    "    stop_year, stop_month, stop_day = map(int, stop.split('-'))\n",
    "    \n",
    "    days = (stop_year - start_year)*365\n",
    "    days += (stop_month - start_month)*30 if stop_month > start_month else (start_month - stop_month)*30\n",
    "    days += stop_day - start_day if stop_day > start_day else start_day - stop_day\n",
    "    \n",
    "    return days\n",
    "\n",
    "df['DURATION'] = df['SIGN_DATE'].apply(find_period) \n",
    "df.drop(columns = ['SIGN_DATE'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d745cd263783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkmeans_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KMeans' is not defined"
     ]
    }
   ],
   "source": [
    "# Klasteryzacja wieku\n",
    "\n",
    "dataset = df[['IS_SUSPENDED', 'AGE']]\n",
    "# dataset = dataset.groupby('AGE').mean()\n",
    "# dataset.reset_index(inplace=True)\n",
    "\n",
    "scaled_dataset = dataset.values\n",
    "\n",
    "kmeans_kwargs = {\n",
    "        \"init\": \"random\",\n",
    "        \"n_init\": 10,\n",
    "        \"max_iter\": 300,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "   \n",
    "# A list holds the SSE values for each k\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(scaled_dataset)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(range(1, 11), sse)\n",
    "plt.xticks(range(1, 11))\n",
    "plt.xlabel(\"n_of_clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "kl = KneeLocator(range(1, 11), sse, curve=\"convex\", direction=\"decreasing\")\n",
    "n_of_clusters = kl.elbow\n",
    "\n",
    "kmeans = KMeans(\n",
    "    init='random',\n",
    "    n_clusters = n_of_clusters,\n",
    "    n_init=50,\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "kmeans.fit(scaled_dataset)\n",
    "\n",
    "df['AGE_CL'] = kmeans.predict(df[[\"IS_SUSPENDED\", \"AGE\"]])\n",
    "\n",
    "df.drop(columns=[\"AGE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak ostatecznie wygląda df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział na dane treningowe i testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[df.columns[1:]], \n",
    "                                                    df[\"IS_SUSPENDED\"], \n",
    "                                                    stratify=df[\"IS_SUSPENDED\"], \n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klasy są niezbalansowane, więc trzeba przeskalować wagi pozytywnej klasy\n",
    "\n",
    "pos = df[\"IS_SUSPENDED\"].sum()/len(df)\n",
    "scalar = (1-pos)/pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(max_depth=5, \n",
    "                  learning_rate=0.1, \n",
    "                  objective= 'binary:logistic',\n",
    "                  n_jobs=-1,\n",
    "                  use_label_encoder = False,\n",
    "                  scale_pos_weight = scalar,\n",
    "                  verbosity=0)\n",
    "                                \n",
    "    \n",
    "xgb_model = XGB.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of XGB classifier on training set: {:.2f}'\n",
    "       .format(xgb_model.score(X_train, y_train)))\n",
    "print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "       .format(xgb_model.score(X_test[X_train.columns], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_importance(xgb_model, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "\n",
    "df_test = pd.read_csv(\"data/PPK_Uczestnicy_TEST.csv\", sep=';')\n",
    "# Mergowanie dwóch csv\n",
    "df_test = pd.merge(\n",
    "    df_test,\n",
    "    pracodawcy,\n",
    "    how='left',\n",
    "    left_on='EMPL_ID',\n",
    "    right_on='ID'\n",
    ")\n",
    "\n",
    "# Dropowanie niepotrzebnych kolumn\n",
    "df_test.drop(columns=['EMPL_ID',  \n",
    "                 'LOGICAL_FACTOR_1',\n",
    "                 'LOGICAL_FACTOR_2',\n",
    "                 'ID',\n",
    "                 'PKD_CODE',\n",
    "                 'PPK_BANK',\n",
    "                 'NUMERICAL_VALUE'], inplace = True)\n",
    "\n",
    "# Te kolumny niby jakoś możnaby wykorzystać, ale wątpliwe, że coś by z tego wynikło\n",
    "df_test.drop(columns =[\"CREATED_AT\", \n",
    "                  \"UOZ_START_DATE\", \n",
    "                  \"UOP_SIGN_DATE\", \n",
    "                  'REGION_CODE',\n",
    "                  'WORK_START', \n",
    "                  'WORK_STOP'], inplace = True)\n",
    "\n",
    "# no i to trzeba wyrzucic heh\n",
    "df_test.drop(columns = [\"RESIGN_DATE\"], inplace = True)\n",
    "\n",
    "# Age to int\n",
    "\n",
    "def to_int(age):\n",
    "    age = age[:age.find(\",\")]\n",
    "    return int(age)\n",
    "\n",
    "df_test[\"AGE\"] = df_test[\"AGE\"].apply(to_int)\n",
    "\n",
    "# Grouping other nationalities into one category '0'\n",
    "\n",
    "unique_nat = df_test['NATIONALITY'].unique()\n",
    "for val in unique_nat:\n",
    "    suma = ( df_test['NATIONALITY'].values == val ).sum()\n",
    "    if suma < 5000:\n",
    "        df_test.loc[df_test.NATIONALITY == val, 'NATIONALITY'] = 0   \n",
    "        \n",
    "# zamiana danych kategorycznych na dummy variables - tworzymy nową kolumnę na każdy możliwy output kolumny, porównaj poprzednią i następną komórkę\n",
    "df_test = pd.get_dummies(df_test, columns = ['SEX', 'COMPANY_SIZE', 'COMPANY_TYPE', 'VOIVODESHIP', 'NATIONALITY','PPK_STAGE'], \n",
    "                         prefix = ['SEX', 'COMPANY_SIZE', 'COMPANY_TYPE', 'VOIVODESHIP', 'NATIONALITY','PPK_STAGE'])\n",
    "\n",
    "# duration - czas od zapisania się do teraz\n",
    "def find_period(start):\n",
    "    stop = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    start_year, start_month, start_day = map(int, start.split('-'))\n",
    "    stop_year, stop_month, stop_day = map(int, stop.split('-'))\n",
    "    \n",
    "    days = (stop_year - start_year)*365\n",
    "    days += (stop_month - start_month)*30 if stop_month > start_month else (start_month - stop_month)*30\n",
    "    days += stop_day - start_day if stop_day > start_day else start_day - stop_day\n",
    "    \n",
    "    return days\n",
    "\n",
    "df_test['DURATION'] = df_test['SIGN_DATE'].apply(find_period) \n",
    "df_test.drop(columns = ['SIGN_DATE'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict( df_test[df_test.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(data = {\"MEMBER_ID\": df_test['MEMBER_ID'],\"IS_SUSPENDED\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('submission.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
